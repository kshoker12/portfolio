# ‚ôüÔ∏è 3D Chess AI Engine ‚Äî Serverless ML Inference, Alpha‚ÄìBeta Search, and 3D Web UI

**Author:** Karandeep ‚ÄúKarn‚Äù Shoker (UBC CS & Statistics) ¬∑ **Rapid summary:** Full‚Äëstack chess system featuring a **React Three Fiber** 3D frontend and a **serverless AWS** backend that serves moves via **alpha‚Äìbeta search** with **neural evaluation** (two ML models) and a **Stockfish** ‚Äúhard‚Äù mode. Built end‚Äëto‚Äëend to highlight graphics, algorithms, MLOps, and cloud architecture. As a ~**1600 ELO** player, building this humbled me (I still can‚Äôt beat Stockfish!) and deepened my positional understanding.

> **What recruiters should notice**
> - Depth across **graphics**, **algorithms**, **machine learning**, and **cloud**.
> - Clear **system design** and **operational excellence** (cost, latency, scalability).
> - Evidence of **experimentation**, **metrics**, and **trade‚Äëoff reasoning**.

---

## 1) System Overview

```
Client (React + R3F/Three.js + Redux) 
   ‚îî‚îÄ‚îÄ> HTTPS (fetch) 
         ‚îî‚îÄ‚îÄ> Amazon API Gateway (REST)
                ‚îî‚îÄ‚îÄ> AWS Lambda (container, ARM64) running FastAPI
                        ‚îú‚îÄ‚îÄ PyTorch MLP (easy/fast)
                        ‚îú‚îÄ‚îÄ scikit-learn MLPRegressor (default/medium)
                        ‚îî‚îÄ‚îÄ Stockfish 16 (hard/accurate)
                              ‚Üë
                      ECR container image (models + engine logic)
```

- **Frontend:** React 18 + **React Three Fiber (R3F)** over Three.js for a smooth 3D chessboard; chess rules and legal move generation from **chess.js**; client state via **Redux Toolkit**.
- **Backend:** **FastAPI** app packaged as an **AWS Lambda** container (**ARM64/Graviton**) behind **Amazon API Gateway**. Returns the best move for a provided FEN with a chosen difficulty, using **alpha‚Äìbeta** + **quiescence** search and a **hybrid evaluation** (neural + classical heuristics), or **Stockfish** at ‚Äúhard.‚Äù
- **Data/Models:** Two learned evaluation models trained using positions from games by **GM‚Äëlevel players** (e.g., Magnus Carlsen, Bobby Fischer, Hikaru Nakamura) labeled with **Stockfish centipawn** evaluations.

---

## 2) Frontend (3D + UX) ‚Äî React Three Fiber, Three.js, Redux

### Rendering & Interaction
- **R3F** scene with board, pieces, camera and lighting; responsive layout; high‚ÄëFPS piece animations; orbit/drag interactions.
- **Chess.js** for rule validation and legal moves; **hover highlights** and **check indicators**.
- **Move list, clocks, resign/draw**, and **VS Bot / Pass‚Äëand‚ÄëPlay** modes.

### State & Performance
- **Redux Toolkit** slices (board/game/UI); memoized selectors to limit re‚Äërenders to **changed squares**.
- **Lazy chunking** of heavy components; request **debounce**; **AbortController** to cancel stale API calls.
- **Mobile** friendly (pointer events) and keyboard accessibility for desktop.

---

## 3) Engine: Algorithms, Data Structures & High‚ÄëLevel Logic

### 3.1 Board Representation & Features
- The ML evaluator consumes a **776‚Äëdimensional feature vector** per position:
  - **12√ó64 piece planes** (one-hot: piece √ó square) ‚Üí 768
  - **Side to move**, **castling rights (4)**, **half‚Äëmove clock**, **full‚Äëmove number**, **material tallies** ‚Üí remaining features
- Classical evaluation adds **material balance**, **piece‚Äësquare tables**, **mobility**, **king safety** penalties, and simple **pawn structure** heuristics.

### 3.2 Search Core
- **Alpha‚ÄìBeta with iterative deepening** and **aspiration windows**.
- **Quiescence** on capture/tactical leafs to mitigate horizon effects.
- **Move ordering:** principal variation moves, **killer moves**, **history heuristic**, **MVV‚ÄëLVA**, and **SEE** (static exchange evaluation).
- **Pruning/Reductions:** **null‚Äëmove pruning**, **late‚Äëmove reductions (LMR)**, futility pruning in quiet nodes.
- **Transposition Table:** **Zobrist hashing** (64‚Äëbit) with **(score, depth, bound)** entries; replacement scheme favors deeper nodes.
- **Blunder filters:** lightweight guards against hanging high‚Äëvalue pieces in shallow lines.
  
**Pseudocode (abridged)**
```text
function SEARCH(node, depth, alpha, beta):
  if depth == 0: return QUIESCENCE(node, alpha, beta)

  if TT.has(node) and TT.depth(node) >= depth:
      entry = TT[node]
      if entry.bound == EXACT: return entry.score
      if entry.bound == LOWER: alpha = max(alpha, entry.score)
      if entry.bound == UPPER: beta  = min(beta,  entry.score)
      if alpha >= beta: return entry.score

  if NULL_MOVE_OK(node) and depth >= R:
      score = -SEARCH(NULL_MOVE(node), depth-1-R, -beta, -beta+1)
      if score >= beta: return beta   // fail-hard

  moves = ORDER(GENERATE(node))  // PV, killers, history, MVV-LVA, SEE
  best = -INF; pv = None
  for (i, m) in enumerate(moves):
      newDepth = depth - 1
      if i > LMR_THRESHOLD and !m.capt: newDepth -= 1   // LMR
      score = -SEARCH(APPLY(node, m), newDepth, -beta, -alpha)
      if score > best:
          best = score; pv = m
          alpha = max(alpha, score)
          if alpha >= beta: break   // cutoff

  TT.store(node, best, depth, bound=BOUND(alpha,beta,best), pv)
  return best
```

### 3.3 Hybrid Evaluation
- **Neural eval (70‚Äì85%)** blended with **classical eval (15‚Äì30%)** depending on difficulty and game phase.
- Classical stabilizes edge cases (e.g., material trades, simple mates) while the neural net captures **positional** signals (space, tension, outposts, pawn structure) hard to encode by hand.

---

## 4) Machine Learning: Data, Training, and the ‚Äú776‚ÄëFeature‚Äù Problem

### 4.1 Dataset & Labeling
- **Source:** PGN games from elite players (Magnus, Fischer, Hikaru, etc.).
- **Extraction:** Sample mid‚Äëgame and late‚Äëopening positions; compute labels with **Stockfish** at calibrated depth (‚âà 15) returning **centipawn** evaluations.
- **De‚Äëduplication** of near‚Äëidentical positions; **balance** across phases (opening/middlegame/endgame) to avoid skew.

### 4.2 Models
- **Model A (PyTorch MLP)** ‚Äî fast inference (‚Äúeasy‚Äù): BN + Dropout, GELU activations; trained with AdamW + cosine LR.
- **Model B (scikit‚Äëlearn `MLPRegressor`)** ‚Äî default (‚Äúmedium‚Äù): `TransformedTargetRegressor(StandardScaler)` around MLP to stabilize targets.
- **‚ÄúHard‚Äù mode** uses **Stockfish 16** directly (no learning), prioritizing strength over latency.

### 4.3 Training Process & Tuning
- **Train/val/test split** on **games**, not just positions (leak prevention).
- **k‚Äëfold cross‚Äëvalidation** for hyper‚Äëparameters: depth, width, dropout, L2, batch size, LR schedule.
- **Early stopping** on validation **MAE**; checkpoint the top‚Äëk models and **ensemble average** candidates.
- **When underperforming**, fixes included:
  - **More data** (especially tactical/middlegame density).
  - **Wider/deeper MLP** (additional hidden layers) with **regularization**.
  - Adjusting **target scaling**; clipping outliers beyond ¬±2000 cp.
  - Rethinking feature interactions instead of aggressive **PCA** (kept raw planes to preserve spatial semantics).

### 4.4 Curse of Dimensionality (776 features)
- 776 features create a **high‚Äëdimensional space** where distances become less informative and generalization suffers.
- Mitigations applied:
  - **L2 weight decay**, **dropout**, and **batch norm** for smoother optimization.
  - **Target engineering:** compress centipawns near 0 (small margins matter) and clip extremes.
  - **Data volume:** aggressively augment with diverse positions to increase coverage of sparse regions.
- **Observed metrics:** **MAE ‚âà 300 cp**, **R¬≤ ‚âà 0.30‚Äì0.42** depending on mix and depth of labels (indicative for a non‚ÄëGPU budget project and good enough for play with search).

---

## 5) AWS Architecture & Ops (Serverless)

### 5.1 Services and Roles
- **AWS Amplify**: CI/CD for the static SPA; **CloudFront CDN**; environment variables (e.g., `VITE_API_BASE`). Custom domain + HTTPS.
- **Amazon API Gateway (REST)**: `POST /v1/api/move` (Lambda proxy), **rate limiting**, **CORS** (restrict origin to Amplify domain).
- **AWS Lambda (container, ARM64/Graviton)**: Runs **FastAPI** with models and engine logic packaged into a single **Docker** image.
- **Amazon ECR**: Container registry for versioned Lambda images.
- **Amazon CloudWatch**: Logs, metrics (p50/p90 latency), alarms on 5XX, throttle, or cold‚Äëstart spikes.
- **(Optional)** **S3** for temporary artifacts; **Provisioned Concurrency** for strict p95 latency SLOs.

### 5.2 Container & Lambda Configuration
- **Base image**: slim Python on ARM64; **manylinux2014** wheels for sklearn/torch to avoid build‚Äëtime compilation.
- **Image size** target: **< 600 MB** by pruning dev packages, caches, and docs.
- **Memory**: 1024 MB; **timeout**: 15 s (tight, but sufficient for depth‚Äëlimited search).
- **Concurrency**: default on‚Äëdemand; enable **provisioned concurrency** when showcasing to a live audience.
- **Model caching**: load models **once** at module import; keep global singletons to survive between invocations.
- **Threading**: disable multithreading for BLAS in Lambda (e.g., `MKL_NUM_THREADS=1`) to avoid noisy neighbors.
- **Cold‚Äëstart** mitigations**:** small dependency graph; lazy import of Stockfish; trimmed fonts/locales; **pydantic** compiled mode.

### 5.3 API Contract
- **Endpoint:** `POST /v1/api/move`
- **Request:**
  ```json
  { "fen": "<FEN>", "difficulty": "easy|medium|hard", "max_depth": 4 }
  ```
- **Response:**
  ```json
  { "best_move": "e2e4", "score_cp": 25, "nodes": 54512, "depth": 4, "pv": ["e2e4", "c7c5", "g1f3"] }
  ```
- **CORS:** `Access-Control-Allow-Origin: https://<your-amplify-domain>`

### 5.4 Cost, Scale, and Reliability
- **Pay‚Äëper‚Äërequest** with automatic horizontal scaling; ideal for **1‚Äì1000** demos/day.
- **ARM64** reduces compute cost vs x86 (~15‚Äì20% improvement).
- **Retry & timeouts** configured at API Gateway; Lambda DLQ/alerts via CloudWatch.
- **Zero servers to patch**; deploys are **atomic** via ECR image tags and Amplify CI.

---

## 6) Results & Benchmarks

- **Evaluator quality (MLP):** ~**300 cp MAE**; **R¬≤ ~ 0.30‚Äì0.42** on held‚Äëout sets labeled by Stockfish at controlled depth.
- **Latency (typical)** by difficulty on Lambda@1GB:
  - `easy` (PyTorch MLP): **70‚Äì150 ms**
  - `medium` (sklearn MLP): **120‚Äì250 ms**
  - `hard` (Stockfish, shallow depth): **300‚Äì800+ ms**
- **UX**: consistent 60 FPS rendering on modern laptops; legal‚Äëmove highlights feel instant; analysis is visibly stronger at ‚Äúhard.‚Äù

> These numbers vary by FEN complexity and depth; the design prioritizes **determinism** and **predictable latency** for demos.

---

## 7) Local Dev & Quickstart

### Frontend
```bash
pnpm install
pnpm dev   # http://localhost:5173
# .env: VITE_API_BASE="https://<api-id>.execute-api.<region>.amazonaws.com/prod"
```

### Backend (local)
```bash
pip install -r requirements.txt
uvicorn app:app --reload  # http://localhost:8000

curl -X POST http://localhost:8000/v1/api/move   -H "Content-Type: application/json"   -d '{"fen":"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1","difficulty":"medium","max_depth":4}'
```

### Deploy (high-level)
1. **Build** Docker image (ARM64) and **push** to **ECR**.
2. Create **Lambda** from image; set **memory/timeout/env**; point **API Gateway** to Lambda proxy.
3. Hook **Amplify** to the frontend repo; set **VITE_API_BASE**; deploy with CI/CD.
4. **Verify** CORS, test latency, add **CloudWatch** alarms.

---

## 8) What I Personally Delivered

- **Architecture**: designed and implemented the full system end‚Äëto‚Äëend.
- **Engine**: alpha‚Äëbeta + quiescence, ordering/pruning, TT with Zobrist, blunder filters.
- **ML**: data pipeline from PGNs ‚Üí features ‚Üí labels; trained **two evaluators**; cross‚Äëvalidated hyper‚Äëparams; handled the **curse of dimensionality**.
- **3D Frontend**: R3F/Three.js scene, input handling, UI/UX polish, performance tuning.
- **DevOps**: containerized FastAPI; **Lambda@ARM64**; API Gateway; Amplify CI/CD; CloudWatch observability; cost/perf optimizations.

---

## 9) Roadmap
- Online multiplayer (WebSockets) + ELO; spectate & analysis boards.
- Post‚Äëgame **eval graph**, **blunder/spike** detection, natural‚Äëlanguage analysis.
- Opening book + endgame tablebases; deeper NN w/ distillation.
- Optional **Provisioned Concurrency** profile for guaranteed p95 latency in live demos.
- Stronger accessibility & mobile tactile feedback.

---

## 10) Skills Demonstrated
**Frontend:** React, TypeScript, React Three Fiber, Three.js, Redux Toolkit, Vite  
**Backend:** FastAPI, REST, Python, chess.js integration  
**Algorithms:** Alpha‚ÄëBeta, Quiescence, TT (Zobrist), Null‚ÄëMove, LMR, Killer/History, SEE, Aspiration Windows  
**ML:** scikit‚Äëlearn, PyTorch, feature engineering, cross‚Äëvalidation, regularization, early stopping  
**Cloud:** AWS Amplify, API Gateway, Lambda (ARM64 containers), ECR, CloudWatch, CORS, CI/CD, cost/perf tuning

---

### Personal Note
As a ~**1600 ELO** player, this project sharpened my understanding of **positional chess**. Encoding ideas like **outposts, space, king safety, and pawn structure** into features/targets taught me *why* certain moves work, while getting crushed by ‚Äúhard‚Äù mode reminded me how far there is to go ü§ù.

